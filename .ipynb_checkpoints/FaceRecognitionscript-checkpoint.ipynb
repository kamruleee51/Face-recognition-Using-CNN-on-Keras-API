{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os, glob, random, sys, time, keras, cv2, itertools, sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.utils.fixes import signature\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentDir=os.getcwd()\n",
    "Dataset = os.listdir(CurrentDir+'/yalefacesData/')\n",
    "\n",
    "Images = []\n",
    "ImageLabel = []\n",
    "\n",
    "for file in Dataset:\n",
    "    if file!='Readme.txt':\n",
    "        fileRead=CurrentDir+'/yalefacesData/'+file \n",
    "        imgRead = io.imread(fileRead, as_grey=True)\n",
    "        Images.append(imgRead) \n",
    "        FileName = os.path.split(file)[1].split(\".\")[0]\n",
    "        labelRead = int(FileName.replace(\"subject\", \"\")) - 1 \n",
    "        ImageLabel.append(labelRead)\n",
    "        \n",
    "print(len(Images))\n",
    "print(Images[0].shape)\n",
    "print(Images[0].dtype)\n",
    "\n",
    "print(len(ImageLabel))\n",
    "print(ImageLabel)\n",
    "\n",
    "\n",
    "# Save the images in Test folder directory \n",
    "for i in range(len(Images)):\n",
    "    image=Images[i]\n",
    "    number='%03d'%i\n",
    "    path=CurrentDir+'/test/'+str(number)+'.png'\n",
    "    cv2.imwrite(path,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceDetectClassifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDataFin = []\n",
    "for i in Images:\n",
    "    facePoints = faceDetectClassifier.detectMultiScale(i)\n",
    "#     print(facePoints[0])\n",
    "    x,y = facePoints[0][:2]\n",
    "    patch = i[y: y + 150, x: x + 150] # Taking the patch of 150x150\n",
    "    imageDataFin.append(patch)\n",
    "    \n",
    "imageDataFin[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(imageDataFin),\n",
    "                                                    np.array(ImageLabel), \n",
    "                                                    train_size=0.9, \n",
    "                                                    random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "nb_classes = 15\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test)\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(149, 150*150)\n",
    "X_test = X_test.reshape(17, 150*150)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelName='ModelSaved'\n",
    "SaveweightName= modelName+'.hdf5'\n",
    "SaveModelName=modelName+'.yaml'\n",
    "\n",
    "savedModel = ModelCheckpoint(SaveweightName,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(SaveModelName, \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, Y_train,\n",
    "                  batch_size=64, \n",
    "                  nb_epoch=100, \n",
    "                  verbose=1, \n",
    "                  validation_data=(X_test, Y_test),\n",
    "                  callbacks= [savedModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the metrics\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid('on')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.grid('on')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(SaveweightName)\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = model.predict_classes(X_test,verbose=1)\n",
    "correct_classified_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_classified_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "print(correct_classified_indices)\n",
    "print(incorrect_classified_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRlabel=[]\n",
    "for i in range(len(X_test)):\n",
    "    X=X_test[i,:]\n",
    "    X=X.reshape(1,22500)\n",
    "#     print(X.shape)\n",
    "    predictLabel=model.predict(X)\n",
    "    PRlabel.append(np.argmax(predictLabel, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_test)):\n",
    "    img=X_test[i,:]\n",
    "    X=img.reshape(1,22500)\n",
    "    X=X.reshape(150,150)\n",
    "    TrueLabel=np.argmax(Y_test[i,:], axis=0)\n",
    "    plt.figure()\n",
    "    plt.title(\"True Label: {}, Predicted Label: {}\".format(TrueLabel,(PRlabel[i])[0]))\n",
    "    plt.imshow(X, cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
